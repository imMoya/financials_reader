{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7e0f336c-e428-4734-bc2a-0dea39445981",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, time\n",
    "import pyspark\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "af1c4cbd-8df7-4cfe-b6e6-5e07cefc19e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DataType, BooleanType, NullType, IntegerType, StringType, MapType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "28504334-dcf5-455d-8f4c-af4324e37809",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf, explode, to_date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f312f63-d4d0-411e-acc3-dd91b9c4f496",
   "metadata": {},
   "source": [
    "# Getting file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "617297fd-c3a8-41ef-b85b-3f6530080ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = 'archive'\n",
    "dir_list = []\n",
    "dir_list += [os.path.join(DIR,file) for file in os.listdir(DIR) if os.path.isdir(os.path.join(DIR, file))]\n",
    "dir_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3586fcc7-8f21-44d4-bb7e-29da75e3a6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get latest quarter\n",
    "quarter_folder = dir_list[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b66cc132-c087-4fae-b2c5-1ae2c70ea7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_files = []\n",
    "json_files += [os.path.join(quarter_folder, file) for file in os.listdir(quarter_folder)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "72ae4c33-bff6-424c-bf57-5078de13e75b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'archive/2022.QTR2/0001493152-22-013349.json'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_file = json_files[0]\n",
    "json_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf194c3-3a47-444d-9836-28483556e24e",
   "metadata": {},
   "source": [
    "# Initialize PySpark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "73e15d52-e5da-479a-9f5c-194a8f6e4795",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = pyspark.sql.SparkSession.builder \\\n",
    "    .appName(\"Decode_json_files\") \\\n",
    "    .config(\"spark.jars\", \"postgresql-42.5.1.jar\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f3a3e4-b9e0-43e8-86fc-e677b9cea6f4",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "702e0477-e8db-4788-9beb-648a1a259385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1 µs, total: 3 µs\n",
      "Wall time: 24.1 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "df = spark.read.option(\"multiline\", \"true\").json(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "63ff6867-d32f-4b4a-9655-f4a5bed48374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- data: struct (nullable = true)\n",
      " |    |-- bs: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- concept: string (nullable = true)\n",
      " |    |    |    |-- label: string (nullable = true)\n",
      " |    |    |    |-- unit: string (nullable = true)\n",
      " |    |    |    |-- value: string (nullable = true)\n",
      " |    |-- cf: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- concept: string (nullable = true)\n",
      " |    |    |    |-- label: string (nullable = true)\n",
      " |    |    |    |-- unit: string (nullable = true)\n",
      " |    |    |    |-- value: string (nullable = true)\n",
      " |    |-- ic: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- concept: string (nullable = true)\n",
      " |    |    |    |-- label: string (nullable = true)\n",
      " |    |    |    |-- unit: string (nullable = true)\n",
      " |    |    |    |-- value: string (nullable = true)\n",
      " |-- endDate: string (nullable = true)\n",
      " |-- quarter: string (nullable = true)\n",
      " |-- startDate: string (nullable = true)\n",
      " |-- symbol: string (nullable = true)\n",
      " |-- year: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bf1c10-9be0-4de9-9b3a-bb1e8aacdee1",
   "metadata": {},
   "source": [
    "### Balance sheet spark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3d9fe05b-c058-485e-ae87-0d2ade67dded",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bs = df.withColumn(\"bs\", explode('data.bs')).select('bs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8dbc8d1e-d555-48e4-91c6-1b781be4f58e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- bs: struct (nullable = true)\n",
      " |    |-- concept: string (nullable = true)\n",
      " |    |-- label: string (nullable = true)\n",
      " |    |-- unit: string (nullable = true)\n",
      " |    |-- value: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_bs.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "887627ce-6972-4fcf-9f02-735fd729ca1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bs = df_bs.select('bs.concept', 'bs.label', 'bs.unit', 'bs.value').distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0f7e13fa-1e7b-4178-9a28-33f3deb6ddd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----+----------+\n",
      "|             concept|               label|unit|     value|\n",
      "+--------------------+--------------------+----+----------+\n",
      "|LiabilitiesNoncur...|Total long-term l...| usd|    253928|\n",
      "|       AssetsCurrent|Total current assets| usd|  21649936|\n",
      "| NotesPayableCurrent|                    | usd|    122175|\n",
      "|RetainedEarningsA...|                    | usd|-177309522|\n",
      "|AdditionalPaidInC...|                    | usd| 195077466|\n",
      "|LiabilitiesAndSto...|Total liabilities...| usd|  22203742|\n",
      "|OtherReceivablesN...|                    | usd|       N/A|\n",
      "| PreferredStockValue|                    | usd|   2656713|\n",
      "|CashAndCashEquiva...|                    | usd|  21372463|\n",
      "|              Assets|        Total assets| usd|  22203742|\n",
      "|  LiabilitiesCurrent|Total current lia...| usd|   1408762|\n",
      "|OperatingLeaseLia...|Operating lease l...| usd|    253928|\n",
      "|OperatingLeaseLia...|                    | usd|    192535|\n",
      "|    CommonStockValue|                    | usd|    116395|\n",
      "|OperatingLeaseRig...|                    | usd|    431961|\n",
      "|AccountsPayableAn...|                    | usd|   1094052|\n",
      "|PrepaidExpenseAnd...|                    | usd|    277473|\n",
      "|PropertyPlantAndE...|                    | usd|    121845|\n",
      "|  StockholdersEquity|Total shareholder...| usd|  20541052|\n",
      "+--------------------+--------------------+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_bs.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23eaed97-24da-4479-9d29-4be342c0cdc5",
   "metadata": {},
   "source": [
    "### Cash flow spark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "95e6c062-0c2d-4f74-867a-8d4e02bd4a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cf = df.withColumn(\"bs\", explode('data.cf')).select('bs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "dee47db4-f723-4329-924d-f5accc53b71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- bs: struct (nullable = true)\n",
      " |    |-- concept: string (nullable = true)\n",
      " |    |-- label: string (nullable = true)\n",
      " |    |-- unit: string (nullable = true)\n",
      " |    |-- value: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d1c07f79-b8db-46b0-97d7-6fef2101fe73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cf = df_cf.select('bs.concept', 'bs.label', 'bs.unit', 'bs.value').distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2f6ba47b-5635-4db8-9503-1f154136e7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----+--------+\n",
      "|             concept|               label|unit|   value|\n",
      "+--------------------+--------------------+----+--------+\n",
      "|       NetIncomeLoss|                    | usd|-6035394|\n",
      "|NetCashProvidedBy...|Net cash used in ...| usd|-5636952|\n",
      "|NetCashProvidedBy...|Net cash used in ...| usd|  -75047|\n",
      "|ProceedsFromWarra...|                    | usd|     N/A|\n",
      "|DepreciationAndAm...|                    | usd|    8468|\n",
      "|ProceedsFromIssua...|                    | usd|     N/A|\n",
      "|IncreaseDecreaseI...|Prepaid expenses ...| usd| -157226|\n",
      "|     InterestPaidNet|                    | usd|    3246|\n",
      "|PaymentsForRepurc...|Redemption of Ser...| usd|     N/A|\n",
      "|PaymentsToAcquire...|Purchase of prope...| usd|   87047|\n",
      "|IncreaseDecreaseI...|Accounts payable ...| usd|  146478|\n",
      "|GainLossOnSaleOfP...|Gain on sale of p...| usd|   10964|\n",
      "|ProceedsFromSaleO...|                    | usd|   12000|\n",
      "|RepaymentsOfShort...|Payments on short...| usd|  181241|\n",
      "|OGEN:StockDividen...|                    | usd|     N/A|\n",
      "|IncreaseDecreaseI...|   Other receivables| usd|   -6987|\n",
      "|CashCashEquivalen...|Net increase (dec...| usd|-5893240|\n",
      "|ShareBasedCompens...|                    | usd|   90247|\n",
      "|NetCashProvidedBy...|Net cash provided...| usd| -181241|\n",
      "+--------------------+--------------------+----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0ca175-226f-40fb-ae51-122f610e9b80",
   "metadata": {},
   "source": [
    "### Income statement spark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ca27619c-d792-429d-964b-3be8c0f8d077",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ic = df.withColumn(\"ic\", explode('data.ic')).select('ic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a56bdba6-3291-45bb-af5a-483062133a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ic: struct (nullable = true)\n",
      " |    |-- concept: string (nullable = true)\n",
      " |    |-- label: string (nullable = true)\n",
      " |    |-- unit: string (nullable = true)\n",
      " |    |-- value: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ic.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f99c0847-b996-49bb-9925-4e8c779b2bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ic = df_ic.select('ic.concept', 'ic.label', 'ic.unit', 'ic.value').distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2517bf3a-dec9-4962-b5fe-51a31ea3309b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----------+---------+\n",
      "|             concept|               label|      unit|    value|\n",
      "+--------------------+--------------------+----------+---------+\n",
      "|OGEN:LocalBusines...|  Local business tax|       usd|      490|\n",
      "|IncomeTaxExpenseB...|                    |       usd|      N/A|\n",
      "|GeneralAndAdminis...|                    |       usd|  1331549|\n",
      "| OperatingIncomeLoss|Loss from operations|       usd| -6054528|\n",
      "|OtherNonoperating...|                    |       usd|    10964|\n",
      "|EarningsPerShareB...|                    |usd/shares|    -0.05|\n",
      "|WeightedAverageNu...|                    |    shares|116394806|\n",
      "|RevenueFromContra...|                    |       usd|    15083|\n",
      "|ResearchAndDevelo...|                    |       usd|  4738062|\n",
      "|NonoperatingIncom...|Total other incom...|       usd|    19134|\n",
      "|IncomeLossFromCon...|Loss before incom...|       usd| -6035394|\n",
      "|InvestmentIncomeI...|                    |       usd|    11906|\n",
      "|     InterestExpense|    Interest expense|       usd|     3246|\n",
      "|   OperatingExpenses|Total operating e...|       usd|  6069611|\n",
      "|       NetIncomeLoss|            Net loss|       usd| -6035394|\n",
      "+--------------------+--------------------+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ic.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d00fc1a-8d87-4a50-8a20-c9a97b82c844",
   "metadata": {},
   "source": [
    "### General information about the company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c46649a1-6779-4c5f-a69d-ff83b8728b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- data: struct (nullable = true)\n",
      " |    |-- bs: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- concept: string (nullable = true)\n",
      " |    |    |    |-- label: string (nullable = true)\n",
      " |    |    |    |-- unit: string (nullable = true)\n",
      " |    |    |    |-- value: string (nullable = true)\n",
      " |    |-- cf: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- concept: string (nullable = true)\n",
      " |    |    |    |-- label: string (nullable = true)\n",
      " |    |    |    |-- unit: string (nullable = true)\n",
      " |    |    |    |-- value: string (nullable = true)\n",
      " |    |-- ic: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- concept: string (nullable = true)\n",
      " |    |    |    |-- label: string (nullable = true)\n",
      " |    |    |    |-- unit: string (nullable = true)\n",
      " |    |    |    |-- value: string (nullable = true)\n",
      " |-- endDate: string (nullable = true)\n",
      " |-- quarter: string (nullable = true)\n",
      " |-- startDate: string (nullable = true)\n",
      " |-- symbol: string (nullable = true)\n",
      " |-- year: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b1446f71-93e9-417d-b4ad-859da8f1ef61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('startDate', to_date(df.startDate, 'yyyy-MM-dd'))\n",
    "df = df.withColumn('endDate',to_date(df.endDate, 'yyyy-MM-dd'))\n",
    "df = df.withColumn('year', df.year.cast('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "37fdd75f-8bca-4d73-9561-3e28e4a1a64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = df.select('year').collect()[0]#show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7b7e3e5e-7c9a-4ba1-bf10-ae685f971a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+-------+----------+------+----+\n",
      "|                data|   endDate|quarter| startDate|symbol|year|\n",
      "+--------------------+----------+-------+----------+------+----+\n",
      "|{[{AssetsCurrent,...|2022-03-31|     Q1|2022-01-01|  OGEN|2022|\n",
      "+--------------------+----------+-------+----------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85548257-5ff3-499b-8ef8-ca8aaa67b6bf",
   "metadata": {},
   "source": [
    "# Track one company over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fc059bef-b231-4b09-9dd5-e4499323df87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_json_in_quarter(dir_quarter):\n",
    "    json_files = []\n",
    "    json_files += [os.path.join(quarter_folder, file) for file in os.listdir(quarter_folder)]\n",
    "    return json_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "357ea084-9ccc-4c2f-872f-1869e1f77f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ticker_in_json_pyspark(json_file):\n",
    "    try:\n",
    "        df = spark.read.option(\"multiline\", \"true\").json(json_file)\n",
    "        return df.select(\"symbol\").collect()[0][0]\n",
    "    except NameError:\n",
    "        print('Please initialize Spark session in variable called \"spark\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bfd390-5240-465e-98a0-e8d0186628e4",
   "metadata": {},
   "source": [
    "Let's get a random ticker so that one can see how "
   ]
  },
  {
   "cell_type": "raw",
   "id": "285406fb-2ede-478b-8d75-0bca1e8a805f",
   "metadata": {},
   "source": [
    "%%timeit\n",
    "tickers = []\n",
    "for json_file in json_files[:100]:\n",
    "    tickers.append(get_ticker_in_json_pyspark(json_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "32f95fe8-a247-497a-ba00-3948fc997e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ticker_in_json(json_file):\n",
    "    with open(json_file, 'r') as jf:\n",
    "        df = json.load(jf)\n",
    "    return df['symbol']"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a4b99b49-ce40-478c-991e-c9cc6ff11327",
   "metadata": {},
   "source": [
    "%%timeit\n",
    "tickers = []\n",
    "for json_file in json_files[:100]:\n",
    "    tickers.append(get_ticker_in_json(json_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ffae7d-3ed5-474a-850d-71eb7241ae2d",
   "metadata": {},
   "source": [
    "### Create database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "52567e54-dcf6-4e00-a9a2-8d15a2736b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import configparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "dfdd7fa4-7e0c-4cce-95c0-39a8fd6a36d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['config.ini']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5492fc33-d953-4300-ab45-b51371ad8ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_NAME = config['DB']['name']\n",
    "DB_USER = config['DB']['user']\n",
    "DB_PASS = config['DB']['pass']\n",
    "DB_HOST = config['DB']['host']\n",
    "DB_PORT = config['DB']['port']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "69911eaf-b8dd-49ec-951b-ce5f3f2b71c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection to database successful\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    conn = psycopg2.connect(database = DB_NAME, user = DB_USER, \n",
    "                            password = DB_PASS, host = DB_HOST,\n",
    "                            port = DB_PORT)\n",
    "    print(\"Connection to database successful\")\n",
    "except:\n",
    "    print(\"Connection to database failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6033e4d4-617b-4ba3-ac7e-1abcaf2c380e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "001c6b80-8931-482e-9b78-7ebedb488aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get lists to be implemented in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "67e0a986-bdf7-4598-b995-81b7d37bbac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_year_qtr_of_dir(filedir):\n",
    "    year = int(re.search('archive/(.*).QTR', filedir).group(1))\n",
    "    qtr = int(re.search('QTR(.*)', filedir).group(1))\n",
    "    return year, qtr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "54620535-9e43-4c8b-ab8a-b2242feb3b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filedir = dir_list[0]\n",
    "year, qtr = get_year_qtr_of_dir(filedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "80ee03a5-50db-44f8-a1ac-a8b85cc067cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_files = get_json_in_quarter(filedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "222fbc4a-98bb-4c29-8d82-6553448c9eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = []\n",
    "for json_file in json_files[:100]:\n",
    "    tickers.append(get_ticker_in_json(json_file))\n",
    "tickers_id = list(enumerate(tickers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4a9b7c82-99fc-448e-b2e6-b024e59da4f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tickers_id[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "28e89800-2297-47b3-b2a9-b9520267e409",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"\"\"\n",
    "            DROP TABLE IF EXISTS summary_archive;\n",
    "            CREATE TABLE IF NOT EXISTS summary_archive (\n",
    "            year INT NOT NULL,\n",
    "            quarter INT NOT NULL, \n",
    "            symbol VARCHAR ( 50 ) NOT NULL,\n",
    "            id INT NOT NULL\n",
    "            )\n",
    "            \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "a9cbb904-cce2-4a99-b03c-91c723bcbc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"\"\"\n",
    "            INSERT INTO summary_archive (year, quarter, symbol, id)\n",
    "            VALUES (%s, %s, %s, %s);\n",
    "            \"\"\", \n",
    "            (year, qtr, tickers_id[0][1], tickers_id[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "e4de5a7c-eac2-43c4-9b86-e35cbf060e21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2009, 2, 'OGEN', 0)]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute(\"SELECT * FROM summary_archive\")\n",
    "a = cur.fetchall()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "7e5cb681-d098-44c4-8902-7daf211f26d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f78ae7a-5f3f-4f89-8726-020fb8faea3b",
   "metadata": {},
   "source": [
    "### BONUS: How to access a DB from pyspark "
   ]
  },
  {
   "cell_type": "raw",
   "id": "40d91e4b-caae-4ee8-a9f5-f2b41d3453b4",
   "metadata": {},
   "source": [
    "spark = pyspark.sql.SparkSession.builder \\\n",
    "    .appName(\"Decode_json_files\") \\\n",
    "    .config(\"spark.jars\", \"postgresql-42.5.1.jar\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "171e9ca1-189a-42ce-b8ba-8a760e9dce06",
   "metadata": {},
   "source": [
    "DB_NAME = \"\"\n",
    "DB_USER = \"\"\n",
    "DB_PASS = \"\"\n",
    "DB_HOST = \"\"\n",
    "DB_PORT = \"\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "9485aa15-e9bd-474c-b335-b51bb3590101",
   "metadata": {},
   "source": [
    "Maybe the url may start with postgresql instead of postgres... Try even running locally"
   ]
  },
  {
   "cell_type": "raw",
   "id": "01b32733-99cf-4922-b89d-3223c8f454e2",
   "metadata": {},
   "source": [
    "df = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", \"jdbc:postgres://hbwuevqw:DUOx89FoaNAqy6vOaf1I9vhN4ExjzT_F@mel.db.elephantsql.com/hbwuevqw\") \\\n",
    "    .option(\"dbtable\", \"Employee\") \\\n",
    "    .option(\"user\", DB_USER) \\\n",
    "    .option(\"password\", DB_PASS) \\\n",
    "    .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "    .load()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark-env",
   "language": "python",
   "name": "pyspark-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
